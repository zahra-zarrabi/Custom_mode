{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference_face_recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahra-zarrabi/FaceRecognition/blob/master/inference_face_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyu1p_x4L51z"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Dropout\n",
        "import cv2\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iq1wHj_XKfF4"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self,number_of_classes):\n",
        "    super().__init__()\n",
        "    self.base=tf.keras.applications.VGG16(include_top=False,weights='imagenet')\n",
        "    # self.conv1=Conv2D(32,(3,3),activation='relu')\n",
        "    # self.conv2=Conv2D(16,(3,3),activation='relu')\n",
        "    self.flatten=Flatten()\n",
        "    self.fc1=Dense(128,activation='relu')\n",
        "    self.fc2=Dense(number_of_classes, activation='softmax')\n",
        "    \n",
        "  def call(self,x):    \n",
        "    for laye in self.base.layers[:-8]:\n",
        "      laye.trainable=False\n",
        "    x=self.base(x)\n",
        "    # x = self.conv1(x)\n",
        "    # x = self.conv2(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc1(x)\n",
        "    output = self.fc2(x)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gaUHbycKgb2"
      },
      "source": [
        "model = MyModel(14)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woCb0N12L_BP",
        "outputId": "f18c1c67-03d7-42ee-899a-b6e5e3bafb08"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/model2/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fdfd5694dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-UvRYYN6wQN",
        "outputId": "82c5e63d-ad7f-423e-fb78-f18856d629a9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyRfc-mTODA1",
        "outputId": "9893cfbb-fb58-47b2-a03b-bb40ef6d834d"
      },
      "source": [
        "image=cv2.imread('1.jpg')\n",
        "image=cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
        "image=cv2.resize(image,(256,256))\n",
        "image=image/255.\n",
        "image=image.reshape(1,256,256,3)\n",
        "y_pred = model(image,training=False)\n",
        "\n",
        "print(np.argmax(y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUyOKdsxtfM6"
      },
      "source": [
        "!pip install retina-face"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvUtrgUHthFm"
      },
      "source": [
        "from retinaface import RetinaFace\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "face=RetinaFace.extract_faces('l2.jpg',align=True)\n",
        "face=face[0]\n",
        "image=cv2.resize(face,(256,256))\n",
        "# plt.imshow(image)\n",
        "plt.imsave('d.jpg',image)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}