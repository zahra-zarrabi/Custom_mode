{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_recognition",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zahra-zarrabi/FaceRecognition/blob/master/face_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTT892u7xVin"
      },
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dVBI9eKQYES"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "configs = {\n",
        "              \"learning_rate\": 0.001,\n",
        "              \"epochs\": 5,\n",
        "              \"batch_size\": 32\n",
        "           }\n",
        "\n",
        "wandb.login()\n",
        "run = wandb.init(project='face-recognition', config=configs)\n",
        "config = wandb.config\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yFI-KJ5ydJG"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Flatten,MaxPooling2D,Dropout\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxW5QX7awvar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f78e337c-c970-4aad-a0fe-710112517f6e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzLJ-DzuQwbb"
      },
      "source": [
        "# **üë©‚Äçüç≥ Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29AJJ25qQvii",
        "outputId": "52ec04a5-59e6-4819-ecf7-f45e9ab7e31f"
      },
      "source": [
        "image_data_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                          horizontal_flip = True,\n",
        "                                          validation_split= 0.2)\n",
        "\n",
        "train_data = image_data_generator.flow_from_directory('/content/drive/MyDrive/7-7 dataset',\n",
        "                                                      class_mode='categorical',\n",
        "                                                      batch_size=config.batch_size,\n",
        "                                                      shuffle=True,\n",
        "                                                      target_size=(224, 224),\n",
        "                                                      subset='training')\n",
        "\n",
        "val_data = image_data_generator.flow_from_directory('/content/drive/MyDrive/7-7 dataset',\n",
        "                                                      class_mode='categorical',\n",
        "                                                      batch_size=config.batch_size,\n",
        "                                                      shuffle=False,\n",
        "                                                      target_size=(224, 224),\n",
        "                                                      subset='validation')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1091 images belonging to 14 classes.\n",
            "Found 268 images belonging to 14 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BYWR2IWxrjx"
      },
      "source": [
        "train_images = next(train_data)[0]\n",
        "plt.figure(figsize = (8,8))\n",
        "for i in range(16):\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  # plt.imshow(train_images[i])\n",
        "  print(train_images.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svbLa4N5zlpS"
      },
      "source": [
        "# üß† Define the Model and the Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ydSJGtQzeia"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self,number_of_classes):\n",
        "    super().__init__()\n",
        "    self.base=tf.keras.applications.VGG16(input_shape=(224,224,3),include_top=False,weights='imagenet')\n",
        "    # self.conv1=Conv2D(32,(3,3),activation='relu')\n",
        "    # self.conv2=Conv2D(16,(3,3),activation='relu')\n",
        "    self.flatten=Flatten()\n",
        "    self.fc1=Dense(256,activation='relu')\n",
        "    self.fc2=Dense(128,activation='relu')\n",
        "    self.fc3=Dense(number_of_classes, activation='softmax')\n",
        "    \n",
        "  def call(self,x):    \n",
        "    for laye in self.base.layers[:-8]:\n",
        "      laye.trainable=False\n",
        "    x=self.base(x)\n",
        "    # x = self.conv1(x)\n",
        "    # x = self.conv2(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc1(x)\n",
        "    x = self.fc2(x)\n",
        "    output = self.fc3(x)\n",
        "    return output"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-qh0Tw4m8RG"
      },
      "source": [
        "model.base.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BYFd9zvmf5W"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLeULNft0srh"
      },
      "source": [
        "model = MyModel(14)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "069ZPoRP0LIe"
      },
      "source": [
        "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXt9TgXWyEI8"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_acc = tf.keras.metrics.CategoricalAccuracy(name='train_acc')\n",
        "\n",
        "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "val_acc = tf.keras.metrics.CategoricalAccuracy(name='val_acc')\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOgL8Q1Jv1Yi"
      },
      "source": [
        "def train_step(images,y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = model(images,training=True)\n",
        "    # print('y_pred',y_pred)\n",
        "    # print('y', y.shape)\n",
        "    loss = loss_function(y,y_pred)\n",
        "  gradients = tape.gradient(loss,model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
        "  train_loss(loss)\n",
        "  # print('y', y)\n",
        "  # print('y_pred', y_pred)\n",
        "  train_acc(y,y_pred)\n",
        "  # print('jnjnj')\n",
        " "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAlGFEV1DP2p"
      },
      "source": [
        "def val_step(images,y):\n",
        "  y_pred = model(images,training=False)\n",
        "  loss = loss_function(y,y_pred)\n",
        "\n",
        "  val_loss(loss)\n",
        "  val_acc(y,y_pred)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygr6k1BzEE3T"
      },
      "source": [
        "def train():\n",
        "  epochs=config.epochs\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    train_acc.reset_states()\n",
        "    val_loss.reset_states()\n",
        "    val_acc.reset_states()\n",
        "\n",
        "    cnt = 0\n",
        "    for cnt in tqdm(range(train_data.__len__())):\n",
        "      images,labels = next(train_data)\n",
        "      train_step(images,labels)\n",
        "    \n",
        "    for cnt in tqdm(range(val_data.__len__())):\n",
        "      images,labels = next(val_data)\n",
        "      val_step(images,labels)\n",
        "\n",
        "    print('epoch:',epoch+1)\n",
        "    print('loss:',train_loss.result())\n",
        "    print('accuracy:',train_acc.result())\n",
        "    print('val loss:',val_loss.result())\n",
        "    print('val accuracy:',val_acc.result())\n",
        "    print('-------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "    #log metrics using wandb.log\n",
        "    wandb.log({'epochs': epoch,\n",
        "                'loss': train_loss.result(),\n",
        "                'acc': train_acc.result(), \n",
        "                'val_loss': val_loss.result(),\n",
        "                'val_acc':val_acc.result()})"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWBFT92HHUQw"
      },
      "source": [
        "#fit\n",
        "train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ww3_W01IGal"
      },
      "source": [
        "model.save_weights('/content/drive/MyDrive/model2/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpmYwyHXIxZ7",
        "outputId": "56e34c08-1015-4386-feba-3b80b1c347dc"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/model1/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7efb0b44f150>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zz9aNA_Gd3N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}