{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "face_recognition",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTT892u7xVin"
      },
      "source": [
        "%%capture\n",
        "!pip install wandb"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dVBI9eKQYES",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2d90e003-9d76-49ff-a674-583adee5c61c"
      },
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "configs = {\n",
        "              \"learning_rate\": 0.001,\n",
        "              \"epochs\": 12,\n",
        "              \"batch_size\": 16\n",
        "           }\n",
        "\n",
        "wandb.login()\n",
        "run = wandb.init(project='face-recognition', config=configs)\n",
        "config = wandb.config\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mzahra_zarrabi\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/zahra_zarrabi/face-recognition/runs/1y9fuegj\" target=\"_blank\">snowy-mountain-2</a></strong> to <a href=\"https://wandb.ai/zahra_zarrabi/face-recognition\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2yFI-KJ5ydJG"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense,Conv2D,Flatten\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxW5QX7awvar"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzLJ-DzuQwbb"
      },
      "source": [
        "# **üë©‚Äçüç≥ Prepare Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29AJJ25qQvii",
        "outputId": "06a0659e-f626-400b-b71c-5f1a3ddd15e0"
      },
      "source": [
        "image_data_generator = ImageDataGenerator(rescale=1./255,\n",
        "                                          horizontal_flip = True,\n",
        "                                          validation_split= 0.2)\n",
        "\n",
        "train_data = image_data_generator.flow_from_directory('/content/drive/MyDrive/7-7 dataset',\n",
        "                                                      class_mode='categorical',\n",
        "                                                      batch_size=config.batch_size,\n",
        "                                                      shuffle=True,\n",
        "                                                      target_size=(512, 512),\n",
        "                                                      subset='training')\n",
        "\n",
        "val_data = image_data_generator.flow_from_directory('/content/drive/MyDrive/7-7 dataset',\n",
        "                                                      class_mode='categorical',\n",
        "                                                      batch_size=config.batch_size,\n",
        "                                                      shuffle=False,\n",
        "                                                      target_size=(512, 512),\n",
        "                                                      subset='validation')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1091 images belonging to 14 classes.\n",
            "Found 268 images belonging to 14 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BYWR2IWxrjx"
      },
      "source": [
        "train_images = next(train_data)[0]\n",
        "plt.figure(figsize = (8,8))\n",
        "for i in range(16):\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(train_images[i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svbLa4N5zlpS"
      },
      "source": [
        "# üß† Define the Model and the Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ydSJGtQzeia"
      },
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self,number_of_classes):\n",
        "    super().__init__()\n",
        "    self.conv1=Conv2D(32,(3,3),input_shape=(512,512,3),activation='relu')\n",
        "    self.conv1=Conv2D(16,(3,3),activation='relu')\n",
        "    self.flatten=Flatten()\n",
        "    self.fc1=Dense(128,activation='relu')\n",
        "    self.fc2=Dense(number_of_classes, activation='softmax')\n",
        "  def call(self,x):\n",
        "  #   input = self.conv1(self.inputs)\n",
        "    x = self.conv1(x)\n",
        "    x = self.flatten(x)\n",
        "    x = self.fc1(x)\n",
        "    output = self.fc2(x)\n",
        "    return output"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLeULNft0srh"
      },
      "source": [
        "model = MyModel(14)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "069ZPoRP0LIe"
      },
      "source": [
        "loss_function = tf.keras.losses.CategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXt9TgXWyEI8"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_acc = tf.keras.metrics.CategoricalAccuracy(name='train_acc')\n",
        "\n",
        "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
        "val_acc = tf.keras.metrics.CategoricalAccuracy(name='val_acc')\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOgL8Q1Jv1Yi"
      },
      "source": [
        "def train_step(images,y):\n",
        "  with tf.GradientTape() as tape:\n",
        "    y_pred = model(images,training=True)\n",
        "    # print('y_pred',y_pred)\n",
        "    # print('y', y.shape)\n",
        "    loss = loss_function(y,y_pred)\n",
        "  gradients = tape.gradient(loss,model.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(gradients,model.trainable_variables))\n",
        "  train_loss(loss)\n",
        "  # print('y', y)\n",
        "  # print('y_pred', y_pred)\n",
        "  train_acc(y,y_pred)\n",
        "  # print('jnjnj')\n",
        " "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAlGFEV1DP2p"
      },
      "source": [
        "def val_step(images,y):\n",
        "  y_pred = model(images,training=False)\n",
        "  loss = loss_function(y,y_pred)\n",
        "\n",
        "  val_loss(loss)\n",
        "  val_acc(y,y_pred)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygr6k1BzEE3T"
      },
      "source": [
        "def train():\n",
        "  epochs=12\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "    train_loss.reset_states()\n",
        "    train_acc.reset_states()\n",
        "    val_loss.reset_states()\n",
        "    val_acc.reset_states()\n",
        "\n",
        "    cnt = 0\n",
        "    for cnt in tqdm(range(train_data.__len__())):\n",
        "      images,labels = next(train_data)\n",
        "      train_step(images,labels)\n",
        "    \n",
        "    for cnt in tqdm(range(val_data.__len__())):\n",
        "      images,labels = next(val_data)\n",
        "      val_step(images,labels)\n",
        "\n",
        "    print('epoch:',epoch+1)\n",
        "    print('loss:',train_loss.result())\n",
        "    print('accuracy:',train_acc.result())\n",
        "    print('val loss:',val_loss.result())\n",
        "    print('val accuracy:',val_acc.result())\n",
        "    print('-------------------------------------------------------------------')\n",
        "\n",
        "\n",
        "    #log metrics using wandb.log\n",
        "    wandb.log({'epochs': epoch,\n",
        "                'loss': train_loss.result(),\n",
        "                'acc': train_acc.result(), \n",
        "                'val_loss': val_loss.result(),\n",
        "                'val_acc':val_acc.result()})"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWBFT92HHUQw",
        "outputId": "8bab0808-30d0-4755-abd5-7beb3e555a98"
      },
      "source": [
        "#fit\n",
        "train()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [11:37<00:00, 10.11s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [03:20<00:00, 11.79s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1\n",
            "loss: tf.Tensor(64.53203, shape=(), dtype=float32)\n",
            "accuracy: tf.Tensor(0.14023831, shape=(), dtype=float32)\n",
            "val loss: tf.Tensor(2.8774166, shape=(), dtype=float32)\n",
            "val accuracy: tf.Tensor(0.16044776, shape=(), dtype=float32)\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [01:30<00:00,  1.32s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:06<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 2\n",
            "loss: tf.Tensor(2.3759487, shape=(), dtype=float32)\n",
            "accuracy: tf.Tensor(0.33638865, shape=(), dtype=float32)\n",
            "val loss: tf.Tensor(2.645093, shape=(), dtype=float32)\n",
            "val accuracy: tf.Tensor(0.2761194, shape=(), dtype=float32)\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [01:30<00:00,  1.31s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:06<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 3\n",
            "loss: tf.Tensor(1.373494, shape=(), dtype=float32)\n",
            "accuracy: tf.Tensor(0.6214482, shape=(), dtype=float32)\n",
            "val loss: tf.Tensor(2.8251455, shape=(), dtype=float32)\n",
            "val accuracy: tf.Tensor(0.39925373, shape=(), dtype=float32)\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [01:30<00:00,  1.31s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:06<00:00,  2.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 4\n",
            "loss: tf.Tensor(0.77343494, shape=(), dtype=float32)\n",
            "accuracy: tf.Tensor(0.8203483, shape=(), dtype=float32)\n",
            "val loss: tf.Tensor(2.8715382, shape=(), dtype=float32)\n",
            "val accuracy: tf.Tensor(0.47761193, shape=(), dtype=float32)\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [01:30<00:00,  1.32s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:07<00:00,  2.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 5\n",
            "loss: tf.Tensor(0.35242534, shape=(), dtype=float32)\n",
            "accuracy: tf.Tensor(0.91109073, shape=(), dtype=float32)\n",
            "val loss: tf.Tensor(2.4293468, shape=(), dtype=float32)\n",
            "val accuracy: tf.Tensor(0.51119405, shape=(), dtype=float32)\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [01:30<00:00,  1.32s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:06<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 6\n",
            "loss: tf.Tensor(0.20442069, shape=(), dtype=float32)\n",
            "accuracy: tf.Tensor(0.9514207, shape=(), dtype=float32)\n",
            "val loss: tf.Tensor(2.1260748, shape=(), dtype=float32)\n",
            "val accuracy: tf.Tensor(0.61567163, shape=(), dtype=float32)\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [01:30<00:00,  1.32s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:06<00:00,  2.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 7\n",
            "loss: tf.Tensor(0.16621923, shape=(), dtype=float32)\n",
            "accuracy: tf.Tensor(0.9615032, shape=(), dtype=float32)\n",
            "val loss: tf.Tensor(2.364826, shape=(), dtype=float32)\n",
            "val accuracy: tf.Tensor(0.5410448, shape=(), dtype=float32)\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [01:31<00:00,  1.32s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:06<00:00,  2.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 8\n",
            "loss: tf.Tensor(0.10163878, shape=(), dtype=float32)\n",
            "accuracy: tf.Tensor(0.96883595, shape=(), dtype=float32)\n",
            "val loss: tf.Tensor(2.1041577, shape=(), dtype=float32)\n",
            "val accuracy: tf.Tensor(0.5932836, shape=(), dtype=float32)\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [01:31<00:00,  1.32s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:06<00:00,  2.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 9\n",
            "loss: tf.Tensor(0.06109427, shape=(), dtype=float32)\n",
            "accuracy: tf.Tensor(0.9871677, shape=(), dtype=float32)\n",
            "val loss: tf.Tensor(2.2924843, shape=(), dtype=float32)\n",
            "val accuracy: tf.Tensor(0.5522388, shape=(), dtype=float32)\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [01:31<00:00,  1.32s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:06<00:00,  2.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10\n",
            "loss: tf.Tensor(0.028911216, shape=(), dtype=float32)\n",
            "accuracy: tf.Tensor(0.9917507, shape=(), dtype=float32)\n",
            "val loss: tf.Tensor(2.0054135, shape=(), dtype=float32)\n",
            "val accuracy: tf.Tensor(0.5895522, shape=(), dtype=float32)\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [01:32<00:00,  1.35s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:06<00:00,  2.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 11\n",
            "loss: tf.Tensor(0.024186462, shape=(), dtype=float32)\n",
            "accuracy: tf.Tensor(0.99541706, shape=(), dtype=float32)\n",
            "val loss: tf.Tensor(2.0855834, shape=(), dtype=float32)\n",
            "val accuracy: tf.Tensor(0.6231343, shape=(), dtype=float32)\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 69/69 [01:33<00:00,  1.36s/it]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:06<00:00,  2.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 12\n",
            "loss: tf.Tensor(0.0055853464, shape=(), dtype=float32)\n",
            "accuracy: tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "val loss: tf.Tensor(1.9512138, shape=(), dtype=float32)\n",
            "val accuracy: tf.Tensor(0.5895522, shape=(), dtype=float32)\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ww3_W01IGal"
      },
      "source": [
        "model.save_weights('/content/drive/MyDrive/model1/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpmYwyHXIxZ7",
        "outputId": "56e34c08-1015-4386-feba-3b80b1c347dc"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/model1/')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7efb0b44f150>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Zz9aNA_Gd3N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}